# ğŸš€ Production ML System

<div align="center">

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green.svg)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-blue.svg)
![MLflow](https://img.shields.io/badge/MLflow-2.8-orange.svg)
![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

**A complete, production-ready machine learning system for customer churn prediction with real-time and batch inference capabilities.**

[Features](#-features) â€¢ [Quick Start](#-quick-start) â€¢ [Architecture](#-architecture) â€¢ [Documentation](#-documentation) â€¢ [Contributing](#-contributing)

</div>

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Architecture](#-architecture)
- [Quick Start](#-quick-start)
- [Project Structure](#-project-structure)
- [API Documentation](#-api-documentation)
- [Testing](#-testing)
- [Deployment](#-deployment)
- [Contributing](#-contributing)
- [License](#-license)

## ğŸ¯ Overview

This is a **production-ready end-to-end machine learning system** that demonstrates best practices in ML engineering, MLOps, and software development. The system includes:

- âœ… Complete ML pipeline (data â†’ features â†’ training â†’ inference)
- âœ… RESTful API with real-time and batch inference
- âœ… Model versioning and experiment tracking (MLflow)
- âœ… Feature store for consistent transformations
- âœ… Canary deployment support
- âœ… React-based monitoring dashboard
- âœ… Comprehensive test suite
- âœ… CI/CD pipeline
- âœ… Docker containerization

## âœ¨ Features

### Core ML Pipeline
- **Data Pipeline**: Synthetic data generation and preprocessing
- **Feature Store**: Consistent feature engineering across training and inference
- **Model Training**: scikit-learn with MLflow experiment tracking
- **Model Registry**: Version management and performance tracking

### API Endpoints
- `POST /api/v1/predict` - Real-time single prediction
- `POST /api/v1/predict/batch` - Batch inference
- `GET /api/v1/models` - List all model versions
- `GET /api/v1/models/{version}` - Get model details
- `GET /api/v1/metrics` - Model performance metrics
- `GET /api/v1/health` - System health check

### Advanced MLOps Features
- **Canary Deployments**: Gradual rollout with traffic splitting
- **A/B Testing**: Compare model versions side-by-side
- **Batch Processing**: Efficient bulk inference
- **Real-time Inference**: Low-latency predictions
- **Metrics Dashboard**: Visualize model performance
- **Prometheus Metrics**: Standard monitoring endpoints

### Quality Assurance
- Unit and integration tests
- Code coverage reporting
- Linting and formatting
- Type safety with Pydantic

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React Frontend â”‚  â† User Interface
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI Backend â”‚  â† REST API
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚Postgresâ”‚ â”‚ MLflow â”‚  â† Data & Models
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

- **Backend**: FastAPI, Python 3.10+
- **ML Framework**: scikit-learn, MLflow
- **Database**: PostgreSQL with SQLAlchemy ORM
- **Frontend**: React, Material-UI, Recharts
- **Containerization**: Docker & Docker Compose
- **CI/CD**: GitHub Actions
- **Monitoring**: Prometheus metrics

## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- Python 3.10+ (for local development)

### Using Docker (Recommended)

```bash
# Clone the repository
git clone https://github.com/yourusername/production-ml-system.git
cd production-ml-system
```

> **Note**: Replace `yourusername` with your GitHub username in all URLs

# Start all services
docker-compose up -d

# Initialize database
docker exec -it ml_api python scripts/init_db.py

# Generate training data
docker exec -it ml_api python scripts/generate_data.py

# Train initial model
docker exec -it ml_api python scripts/train_model.py
```

**Access the services:**
- ğŸŒ **Frontend Dashboard**: http://localhost:3000
- ğŸ“š **API Documentation**: http://localhost:8000/docs
- ğŸ“Š **MLflow UI**: http://localhost:5000
- ğŸ” **API Health**: http://localhost:8000/api/v1/health

### Local Development

```bash
# Install dependencies
pip install -r requirements.txt

# Set up environment
cp .env.example .env
# Edit .env with your configuration

# Initialize database
alembic upgrade head

# Generate data and train model
python scripts/generate_data.py
python scripts/train_model.py

# Start API server
uvicorn app.main:app --reload --port 8000

# In another terminal, start frontend
cd frontend
npm install
npm run dev
```

## ğŸ“ Project Structure

```
production-ml-system/
â”œâ”€â”€ app/                      # FastAPI application
â”‚   â”œâ”€â”€ api/v1/              # API routes
â”‚   â”œâ”€â”€ ml/                  # ML components
â”‚   â”‚   â”œâ”€â”€ model_manager.py # Model loading & serving
â”‚   â”‚   â””â”€â”€ trainer.py       # Model training
â”‚   â”œâ”€â”€ services/            # Business logic
â”‚   â”œâ”€â”€ feature_store/       # Feature engineering
â”‚   â”œâ”€â”€ models.py            # Database models
â”‚   â”œâ”€â”€ schemas.py           # Pydantic schemas
â”‚   â””â”€â”€ main.py              # FastAPI app
â”œâ”€â”€ scripts/                  # Utility scripts
â”‚   â”œâ”€â”€ train_model.py       # Training pipeline
â”‚   â”œâ”€â”€ batch_inference.py   # Batch processing
â”‚   â”œâ”€â”€ generate_data.py     # Data generation
â”‚   â””â”€â”€ setup_canary.py      # Canary deployment
â”œâ”€â”€ tests/                   # Test suite
â”‚   â”œâ”€â”€ unit/                # Unit tests
â”‚   â””â”€â”€ integration/         # Integration tests
â”œâ”€â”€ frontend/                # React dashboard
â”‚   â”œâ”€â”€ src/
â”‚   â””â”€â”€ public/
â”œâ”€â”€ docker/                   # Docker configuration
â”œâ”€â”€ .github/workflows/        # CI/CD pipeline
â”œâ”€â”€ alembic/                 # Database migrations
â”œâ”€â”€ docker-compose.yml       # Docker Compose config
â””â”€â”€ requirements.txt         # Python dependencies
```

## ğŸ“š API Documentation

### Real-time Prediction

```bash
curl -X POST http://localhost:8000/api/v1/predict \
  -H "Content-Type: application/json" \
  -d '{
    "customer": {
      "customer_id": "CUST_00001",
      "age": 45,
      "tenure": 12,
      "monthly_charges": 70.5,
      "total_charges": 846.0,
      "contract_type": "Month-to-month",
      "payment_method": "Electronic check",
      "paperless_billing": true,
      "gender": "Male",
      "partner": false,
      "dependents": false,
      "phone_service": true,
      "multiple_lines": false,
      "internet_service": "Fiber optic",
      "online_security": false,
      "online_backup": false,
      "device_protection": false,
      "tech_support": false,
      "streaming_tv": true,
      "streaming_movies": true
    }
  }'
```

### Batch Inference

```bash
curl -X POST http://localhost:8000/api/v1/predict/batch \
  -H "Content-Type: application/json" \
  -d '{
    "customers": [...]
  }'
```

Full API documentation available at http://localhost:8000/docs

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=app --cov-report=html

# Run specific test suites
pytest tests/unit/
pytest tests/integration/
```

## ğŸš¢ Deployment

See [DEPLOYMENT.md](DEPLOYMENT.md) for detailed deployment instructions, including:
- Production configuration
- Canary deployment setup
- Scaling strategies
- Monitoring setup

## ğŸ“– Documentation

- [QUICKSTART.md](QUICKSTART.md) - 5-minute quick start guide
- [ARCHITECTURE.md](ARCHITECTURE.md) - System architecture details
- [DEPLOYMENT.md](DEPLOYMENT.md) - Deployment and operations guide
- [CONTRIBUTING.md](CONTRIBUTING.md) - Contribution guidelines
- [PROJECT_SHOWCASE.md](PROJECT_SHOWCASE.md) - Project showcase details

## ğŸ¤ Contributing

Contributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“Š Project Stats

- **Lines of Code**: 3000+
- **Components**: 20+ modules
- **API Endpoints**: 8+ REST endpoints
- **Test Coverage**: Unit + Integration tests
- **Services**: 4 containerized services

## ğŸ“ Use Cases

- **Portfolio Project**: Showcase ML engineering skills
- **Learning Resource**: Understand production ML systems
- **Template**: Starting point for ML projects
- **Interview Prep**: Demonstrate full-stack ML knowledge

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

Built as a showcase of production-ready ML system architecture and MLOps best practices.

---

<div align="center">

**â­ If you find this project helpful, please give it a star! â­**

Made with â¤ï¸ for the ML community

</div>
